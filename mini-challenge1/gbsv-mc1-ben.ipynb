{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width: 30%; float: right; margin: 10px; margin-right: 5%;\">\n",
    "    <img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/d/d3/FHNW_Logo.svg/2560px-FHNW_Logo.svg.png\" width=\"500\" style=\"float: left; filter: invert(50%);\"/>\n",
    "</div>\n",
    "\n",
    "<h1 style=\"text-align: left; margin-top: 10px; float: left; width: 60%;\">\n",
    "    gbvs Mini-Challenge 1 <br> \n",
    "</h1>\n",
    "\n",
    "<p style=\"clear: both; text-align: left;\">\n",
    "    Bearbeitet durch Si Ben Tran im HS 2023.<br>Bachelor of Science FHNW in Data Science.\n",
    "</p>\n",
    "\n",
    "In dieser Mini-Challenge werden LE1 und LE2 von gbsv geprüft. Jede:r Studierende:r hat eine individualisierte Aufgabenstellung. Die Abgabe soll ebenfalls einzigartig sein. Dazu wird in dieser Mini-Challenge ein Steckbrief über ein Land in Form von Experimenten in Bild- und Signalverarbeitung zusammengestellt. Das heisst, du wählst passend zu deinem gewählten Land (siehe Google Docs) und den dir zugeordneten Aufgaben Bilder und Signale aus. Wenn du z.B. die Schweiz hast, könntest du Löcher in Bildern vom Emmentalerkäse finden. Die Programmiersprache und die Code-Dokumentation darf frei gewählt werden. Sofern nicht anders erwähnt, dürfen vorhandene Bibliotheken verwendet werden. Gebe die Quellen deiner Daten und ggf. deines Codes an. \n",
    "\n",
    "Teil der Mini-Challenge ist es, die Abgabe von jemand anderem zu bewerten. \n",
    "\n",
    "Abgaben (Termin siehe Spaces): Code, Resultate und Report gemäss Vorlage. Fürs Peer-Grading sollen die Abgaben anonymisiert sein. \n",
    "Google Docs: Ländereinschreibung\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Grundlagen Bild- und Signalverarbeitung (LE1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Bildeigenschaften\n",
    "Suche verschiedene Bilder unterschiedlicher Szenen passend zu deinem Land oder nehme selbst welche auf. Die Bilder sollen sich eignen, um Anpassungen der Bildeigenschaften {'Wertebereiche von Pixeln, Schärfe, Farbräume (Korrektur oder Transformationen)'} in Experimenten zu demonstrieren. Messe dazu zuerst auf deinen Bildern die dir zugeordneten Bildeigenschaften mittels geeigneten Metriken. Definiere danach ein Ziel, wie die dir zugeordneten Bildeigenschaften verändert werden sollen. Definiere ein paar Experimente, um dieses Ziel zu erreichen, und führe die Experimente mit deinen Bildern und geeigneten Methoden aus. Analysiere die Histogramme der ursprünglichen Bilder und während deinen Experimenten. Führe ggf. eine Histogramm-Entzerrung (Englisch: histogram equalization) durch. Diskutiere deine Daten-, Parameter- und Methodenwahl und die erzielten Ergebnisse. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Science standard libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Operating System\n",
    "import os\n",
    "\n",
    "# image libraries\n",
    "from PIL import Image\n",
    "from skimage import color, exposure\n",
    "from skimage.metrics import peak_signal_noise_ratio\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1 Bilder Laden \n",
    "\n",
    "In einem ersten Schritt wurden 20 Bilder aus dem Internet heruntergeladen. Die letzten fünf weitere wurden durch Dall-E generiert.   \n",
    "Gesamthaft befindet sich in unserem Bilder Pool 25 Dateien, die numeriert sind.   \n",
    "In einem ersten Schritt visualisieren wir die 25 Bilder und wählen dann für jedes Experiment jeweils zwei passende Bilder aus.  \n",
    "Gesamthaft werden es sechs Bilder sein für die drei Experimente (Wertebereich von Pixeln, Schärfe, Farbräume (Korrektur oder Transformationen))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of picture filenames\n",
    "dateinamen = [\"1.jpg\", \"2.jpg\", \"3.jpg\", \"4.jpg\", \"5.jpg\", \"6.jpg\", \"7.jpg\", \"8.jpg\", \"9.jpg\", \"10.jpg\", \"11.jpg\", \"12.jpg\", \"13.jpg\", \"14.jpg\", \"15.jpg\", \"16.jpg\", \"17.jpg\", \"18.jpg\", \"19.jpg\", \"20.jpg\", \"21.png\", \"22.png\", \"23.png\", \"24.png\", \"25.png\"]\n",
    "\n",
    "# Create a list to store the images\n",
    "images = []\n",
    "\n",
    "# Loop through the filenames and read and store the images in the list\n",
    "for dateiname in dateinamen:\n",
    "    # Read the image using PIL\n",
    "    image = Image.open(f\"data/images/{dateiname}\")\n",
    "    images.append(image)\n",
    "\n",
    "# Create a 5x5 grid for the subplots\n",
    "fig, axes = plt.subplots(5, 5, figsize=(15, 12))\n",
    "\n",
    "# Loop through the images and display them with titles\n",
    "for i, image in enumerate(images):\n",
    "    # Get image size in pixels\n",
    "    width, height = image.size\n",
    "\n",
    "    # Get file size in kilobytes\n",
    "    file_size_kb = os.path.getsize(f\"data/images/{dateinamen[i]}\") / 1024\n",
    "\n",
    "    # Calculate aspect ratio\n",
    "    aspect_ratio = width / height\n",
    "\n",
    "    # Choose the appropriate subplot for the current image\n",
    "    ax = axes[i // 5, i % 5]\n",
    "\n",
    "    # Display the image on the subplot\n",
    "    ax.imshow(image)\n",
    "    ax.axis('off')  # Turn off axis labels\n",
    "\n",
    "    # Create a title with file name, resolution, and file size\n",
    "    title = f\"{dateinamen[i]} ({width}x{height}, {file_size_kb:.2f} KB)\"\n",
    "    \n",
    "    # Add the aspect ratio on a new line below the title\n",
    "    title += f\"\\nAspect Ratio: {aspect_ratio:.2f}\"\n",
    "    ax.set_title(title, fontsize=10)\n",
    "\n",
    "# Adjust spacing between subplots\n",
    "plt.subplots_adjust(wspace=0.3, hspace=0.3)\n",
    "\n",
    "# Set Seaborn style\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2 Bilder selektieren & geeignete Metriken\n",
    "\n",
    "Wir selektieren für jedes Experiment zwei Bilder und messen die geeigneten Bildmetriken im verlaufe der Experimente. \n",
    "Hier schreiben wir die Funktionen die wir dafür benötigen.\n",
    "\n",
    "Folgende Metriken werden als geeignet erachtet: \n",
    "RMSE - Root Mean Square Error - Ein Vergleich der Pixelwerte zwischen zwei Bildern.   \n",
    "Die Histogramme der Bilder mit dem Parameter log=True, um die Verteilung der Pixelwerte vor und nach der Bearbeitung zu sehen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selektieren der Bilder und speicher in einer Liste\n",
    "image_pixel = [\"2.jpg\", \"21.png\"]\n",
    "image_schaerfe = [\"10.jpg\", \"19.jpg\"]\n",
    "image_farbraum = [\"11.jpg\", \"22.png\"]\n",
    "\n",
    "# visualize images in 3x2 grid \n",
    "fig, axes = plt.subplots(3, 2, figsize=(15, 12))\n",
    "for i, image in enumerate(image_pixel + image_schaerfe + image_farbraum):\n",
    "    ax = axes[i // 2, i % 2]\n",
    "    ax.imshow(Image.open(f\"data/images/{image}\"))\n",
    "    ax.axis('off')\n",
    "    ax.set_title(image, fontsize=10)\n",
    "plt.subplots_adjust(wspace=0, hspace=0.1)\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.suptitle(\"Bilderauswahl für die Experimente \\n Wertebereich von Pixeln, Schärfe, Farbräume\", fontsize=20)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metriken für die Bilder definieren \n",
    "def calc_rmse_images(image1, image2):\n",
    "    \"\"\"\n",
    "    Calculate the Root Mean Square Error (RMSE) between two images.\n",
    "\n",
    "    Parameters:\n",
    "    image1 (numpy array): The first image represented as a numpy array\n",
    "    image2 (numpy array): The second image represented as a numpy array\n",
    "\n",
    "    Returns:\n",
    "    float: The RMSE between the two images\n",
    "    \"\"\"\n",
    "    # Check if both images have the same shape\n",
    "    if image1.shape != image2.shape:\n",
    "        raise ValueError(\"Both images must have the same shape\")\n",
    "\n",
    "    # Calculate the RMSE\n",
    "    rmse = np.sqrt(np.mean((image1 - image2)**2))\n",
    "    return rmse\n",
    "\n",
    "def image_and_histo(image1, image2, title1, title2, log_scale=False):\n",
    "    \"\"\"\n",
    "    Plots two images and their RGB histograms in a 2x2 subplot each.\n",
    "\n",
    "    Parameters:\n",
    "    - image1, image2: 3D numpy arrays representing RGB images.\n",
    "    - title1, title2: Titles for the subplots of image1 and image2 respectively.\n",
    "    - log_scale: Boolean. If True, sets the y-axis of the histogram to logarithmic scale.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Helper function to plot RGB histogram for an image\n",
    "    def plot_rgb_histogram(ax, img, log_scale):\n",
    "        colors = ('r', 'g', 'b')\n",
    "        total_pixels = img.shape[0] * img.shape[1]\n",
    "        for i, color in enumerate(colors):\n",
    "            histogram, bin_edges = np.histogram(\n",
    "                img[:, :, i], \n",
    "                bins=256, \n",
    "                range=(0, 255)\n",
    "            )\n",
    "            normalized_histogram = histogram / total_pixels  # Normalize histogram\n",
    "            ax.plot(bin_edges[0:-1], \n",
    "                    normalized_histogram, \n",
    "                    color=color)\n",
    "        if log_scale:\n",
    "            ax.set_yscale('log')  # Set logarithmic scale on y-axis\n",
    "        ax.set_xlim([0, 255])\n",
    "\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(12, 6))\n",
    "    \n",
    "    # Display image1\n",
    "    axs[0, 0].imshow(image1)\n",
    "    axs[0, 0].set_title(title1)\n",
    "\n",
    "    # Plot RGB histogram for image1\n",
    "    plot_rgb_histogram(axs[0, 1], image1, log_scale)\n",
    "    axs[0, 1].set_title(f\"{'Log-Scaled ' if log_scale else ''}RGB Histogram for {title1}\")\n",
    "\n",
    "    # Display image2\n",
    "    axs[1, 0].imshow(image2)\n",
    "    axs[1, 0].set_title(title2)\n",
    "\n",
    "    # Plot RGB histogram for image2\n",
    "    plot_rgb_histogram(axs[1, 1], image2, log_scale)\n",
    "    axs[1, 1].set_title(f\"{'Log-Scaled ' if log_scale else ''}RGB Histogram for {title2}\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.3 Ziel definieren\n",
    "\n",
    "Nachdem wir uns die Eigenschaften der Bilder angeschaut haben, definieren wir ein Ziel für jedes Experiment.\n",
    "\n",
    "| Experiment | Ziel | Bilder |\n",
    "| --- | --- | --- |\n",
    "| Wertebereich von Pixeln | Auf einzelne Pixel Addition und Subtraktion durchführen können. <br> Wertebereich von Bildern Filtern zu können | 2, 21 |\n",
    "| Schärfe | Bild schärfer und unscharf machen zu können. | 10, 19 |\n",
    "| Farbräume (Korrektur oder Transformationen) | Helligkeit eines Bildes ändern können. <br> Kontrast eines Bildes verändern. | 11, 22 | \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.4 Experiment Wertebereich von Pixeln\n",
    "\n",
    "In diesem Experiment versuchen wir den Wertebereich des Bildes zu ändern. Dabei versuchen wir in einem ersten Exerperiment durch Addition und Subtraktion der Bilder 2 und 21 das Bild zu verändern und vergleichen anschliessend beide Resultate miteinandner.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.4.1 Experiment durch Addition / Subtraktion\n",
    "\n",
    "Wir schreiben eine Funktion, die es uns erlaubt, eine beliebige Zahl auf die Pixelwerte des Bildes zu addieren.   \n",
    "Pixelwerte die über 255 werden auf 255 geclippt und Pixelwerte die unter 0 fallen werden auf 0 geclippt.   \n",
    "Die Funktion sollte uns die Möglichkeit geben, auszuwählen, welchen Farbkanal wir verändern möchten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_value_range(image: np.ndarray, add_r: int, add_g: int, add_b: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Ändert den Wertebereich eines Bildes, indem es eine bestimmte Zahl zu den Pixelwerten der einzelnen Farbkanäle addiert.\n",
    "    \n",
    "    Parameters:\n",
    "    image (np.ndarray): Das Eingabebild als Numpy-Array mit Form (Höhe, Breite, 3).\n",
    "    add_r (int): Der zu addierende Wert für den Rotkanal.\n",
    "    add_g (int): Der zu addierende Wert für den Grünkanal.\n",
    "    add_b (int): Der zu addierende Wert für den Blaukanal.\n",
    "    \n",
    "    Returns:\n",
    "    np.ndarray: Das bearbeitete Bild.\n",
    "    \"\"\"\n",
    "    # Überprüfen, ob das Bild die korrekte Form hat\n",
    "    if image.ndim != 3 or image.shape[2] != 3:\n",
    "        raise ValueError(\"Das Eingabebild muss die Form (Höhe, Breite, 3) haben.\")\n",
    "    \n",
    "    # Erstellen einer Kopie des Bildes, um das Originalbild nicht zu verändern\n",
    "    new_image = image.copy().astype(np.int16)  # Konvertieren zu int16, um Überlauf zu verhindern\n",
    "    \n",
    "    # Addieren der Werte zu den entsprechenden Kanälen\n",
    "    new_image[:, :, 0] += add_r  # Rotkanal\n",
    "    new_image[:, :, 1] += add_g  # Grünkanal\n",
    "    new_image[:, :, 2] += add_b  # Blaukanal\n",
    "    \n",
    "    # Clipping der Pixelwerte, um sicherzustellen, dass sie im gültigen Bereich bleiben\n",
    "    np.clip(new_image, 0, 255, out=new_image)\n",
    "    \n",
    "    # Konvertieren zurück zu uint8\n",
    "    new_image = new_image.astype(np.uint8)\n",
    "\n",
    "    # Rückgabe des bearbeiteten Bildes\n",
    "    return Image.fromarray(new_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wertebereich der Pixel manipulieren\n",
    "image_2_1 = change_value_range(image = np.array(Image.open(\"data/images/2.jpg\")), \n",
    "                               add_r=100, \n",
    "                               add_g=100, \n",
    "                               add_b=100)\n",
    "\n",
    "image_2_2 = change_value_range(image = np.array(Image.open(\"data/images/2.jpg\")),\n",
    "                                add_r=-100,\n",
    "                                add_g=-100,\n",
    "                                add_b=-100)\n",
    "\n",
    "image_21_1 = change_value_range(image = np.array(Image.open(\"data/images/21.png\")),\n",
    "                                add_r=150,\n",
    "                                add_g=150,\n",
    "                                add_b=150)\n",
    "\n",
    "image_21_2 = change_value_range(image = np.array(Image.open(\"data/images/21.png\")),\n",
    "                                add_r=-150,\n",
    "                                add_g=-150,\n",
    "                                add_b=-150)\n",
    "\n",
    "# Calculate MSE for the images \n",
    "rmse_2_1 = calc_rmse_images(image1 = np.array(Image.open(\"data/images/2.jpg\")), image2 = np.array(image_2_1))\n",
    "rmse_2_2 = calc_rmse_images(image1 = np.array(Image.open(\"data/images/2.jpg\")), image2 = np.array(image_2_2))\n",
    "rmse_21_1 = calc_rmse_images(image1 = np.array(Image.open(\"data/images/21.png\")), image2 = np.array(image_21_1))\n",
    "rmse_21_2 = calc_rmse_images(image1 = np.array(Image.open(\"data/images/21.png\")), image2 = np.array(image_21_2))\n",
    "# calculate MSE for orginal image\n",
    "rmse_2 = calc_rmse_images(image1 = np.array(Image.open(\"data/images/2.jpg\")), image2 = np.array(Image.open(\"data/images/2.jpg\")).copy())\n",
    "rmse_21 = calc_rmse_images(image1 = np.array(Image.open(\"data/images/21.png\")), image2 = np.array(Image.open(\"data/images/21.png\")).copy())\n",
    "\n",
    "# Calculate PSNR for the images\n",
    "psnr_2_1 = peak_signal_noise_ratio(np.array(Image.open(\"data/images/2.jpg\")), np.array(image_2_1))\n",
    "psnr_2_2 = peak_signal_noise_ratio(np.array(Image.open(\"data/images/2.jpg\")), np.array(image_2_2))\n",
    "psnr_21_1 = peak_signal_noise_ratio(np.array(Image.open(\"data/images/21.png\")), np.array(image_21_1))\n",
    "psnr_21_2 = peak_signal_noise_ratio(np.array(Image.open(\"data/images/21.png\")), np.array(image_21_2))\n",
    "# calculate psnr for orginal image\n",
    "psnr_2 = peak_signal_noise_ratio(np.array(Image.open(\"data/images/2.jpg\")), np.array(Image.open(\"data/images/2.jpg\")).copy())\n",
    "psnr_21 = peak_signal_noise_ratio(np.array(Image.open(\"data/images/21.png\")), np.array(Image.open(\"data/images/21.png\")).copy())\n",
    "\n",
    "# visualize images in 2x3 grid\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 12))\n",
    "axes[0, 1].imshow(Image.open(\"data/images/2.jpg\"))\n",
    "axes[0, 1].axis('off')\n",
    "axes[0, 1].set_title(f\"Originalbild \\nRMSE: {rmse_2:.2f}, PSNR: {psnr_2:.2f}\" , fontsize=10)\n",
    "axes[0, 2].imshow(image_2_1)\n",
    "axes[0, 2].axis('off')\n",
    "axes[0, 2].set_title(f\"Pixelwerte +100\\nRMSE: {rmse_2_1:.2f}, PSNR: {psnr_2_1:.2f}\", fontsize=10)\n",
    "axes[0, 0].imshow(image_2_2)\n",
    "axes[0, 0].axis('off')\n",
    "axes[0, 0].set_title(f\"Pixelwerte -100\\nRMSE: {rmse_2_2:.2f}, PSNR: {psnr_2_2:.2f}\", fontsize=10)\n",
    "axes[1, 1].imshow(Image.open(\"data/images/21.png\"))\n",
    "axes[1, 1].axis('off')\n",
    "axes[1, 1].set_title(f\"Originalbild \\nRMSE: {rmse_21:.2f}, PSNR: {psnr_21:.2f}\", fontsize=10)\n",
    "axes[1, 2].imshow(image_21_1)\n",
    "axes[1, 2].axis('off')\n",
    "axes[1, 2].set_title(f\"Pixelwerte +150\\nRMSE: {rmse_21_1:.2f}, PSNR: {psnr_21_1:.2f}\", fontsize=10)\n",
    "axes[1, 0].imshow(image_21_2)\n",
    "axes[1, 0].axis('off')\n",
    "axes[1, 0].set_title(f\"Pixelwerte -150\\nRMSE: {rmse_21_2:.2f}, PSNR: {psnr_21_2:.2f}\", fontsize=10)\n",
    "\n",
    "plt.subplots_adjust(wspace=0.1, hspace=0.1)\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.suptitle(\"Pixelwerte verändern\", fontsize=20, y=0.9)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogramm der Bilder\n",
    "image_and_histo(image1=np.array(Image.open(\"data/images/2.jpg\")), \n",
    "                image2=np.array(image_2_1), \n",
    "                title1=\"Originalbild\", \n",
    "                title2=\"Pixelwerte +100\",\n",
    "                log_scale=True)\n",
    "\n",
    "image_and_histo(image1=np.array(Image.open(\"data/images/2.jpg\")),\n",
    "                image2=np.array(image_2_2),\n",
    "                title1=\"Originalbild\",\n",
    "                title2=\"Pixelwerte -100\", \n",
    "                log_scale=True)\n",
    "\n",
    "image_and_histo(image1=np.array(Image.open(\"data/images/21.png\")),\n",
    "                image2=np.array(image_21_1),\n",
    "                title1=\"Originalbild\",\n",
    "                title2=\"Pixelwerte +150\",\n",
    "                log_scale=True)\n",
    "\n",
    "image_and_histo(image1=np.array(Image.open(\"data/images/21.png\")),\n",
    "                image2=np.array(image_21_2),\n",
    "                title1=\"Originalbild\",\n",
    "                title2=\"Pixelwerte -150\",\n",
    "                log_scale=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.4.2 Experiment durch Filtern \n",
    "\n",
    "Die Idee in diesem Experiment ist es nach einen bestimmten Pixel Wertebereich zu filtern und anschliessend die Bilder zu visualisieren und zu vergleichen.\n",
    "\n",
    "Auch hier schreiben wir eine Funktion, die es uns ermöglicht, die Filterung auf die einzelnen Farbkanäle anzuwenden. Um zu überprüfen, ob die Filterung funktioniert, filtern wir den Farbkanal Rot mit einem Wertebereich von 0 bis 0, also bzw eine Entfernung und erwarten ein Bild mit blau und grün tönen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_pixel_values(image_path, filter_r, filter_g, filter_b):\n",
    "    # Bild einlesen\n",
    "    image = Image.open(image_path)\n",
    "    \n",
    "    # Umwandeln in ein Numpy-Array\n",
    "    img_array = np.array(image)\n",
    "\n",
    "    # Überprüfen, ob das Bild die korrekte Form hat\n",
    "    if img_array.ndim != 3 or img_array.shape[2] != 3:\n",
    "        raise ValueError(\"Das Eingabebild muss die Form (Höhe, Breite, 3) haben.\")\n",
    "    \n",
    "    # Pixelwerte filtern\n",
    "    red_channel = np.where((img_array[:,:,0] >= filter_r[0]) & (img_array[:,:,0] <= filter_r[1]), img_array[:,:,0], 0)\n",
    "    green_channel = np.where((img_array[:,:,1] >= filter_g[0]) & (img_array[:,:,1] <= filter_g[1]), img_array[:,:,1], 0)\n",
    "    blue_channel = np.where((img_array[:,:,2] >= filter_b[0]) & (img_array[:,:,2] <= filter_b[1]), img_array[:,:,2], 0)\n",
    "    \n",
    "    # Set correct dtype for image array\n",
    "    filtered_img_array = np.stack([red_channel, green_channel, blue_channel], axis=2).astype(np.uint8)\n",
    "    \n",
    "    # Bild aus gefiltertem Array erstellen\n",
    "    filtered_image = Image.fromarray(filtered_img_array)\n",
    "    \n",
    "    # Return filtered image\n",
    "    return filtered_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktion testen indem Rot weg gefiltert wird\n",
    "image_2_1_filter = filter_pixel_values(image_path='data/images/2.jpg', \n",
    "                                       filter_r = (0, 0), \n",
    "                                       filter_g = (0, 255), \n",
    "                                       filter_b = (0, 255))\n",
    "\n",
    "image_2_2_filter = filter_pixel_values(image_path='data/images/2.jpg',\n",
    "                                        filter_r = (0, 255),\n",
    "                                        filter_g = (0, 0),\n",
    "                                        filter_b = (0, 255))\n",
    "\n",
    "image_21_1_filter = filter_pixel_values(image_path='data/images/21.png',\n",
    "                                        filter_r = (0, 0),\n",
    "                                        filter_g = (0, 255),\n",
    "                                        filter_b = (0, 255))\n",
    "\n",
    "image_21_2_filter = filter_pixel_values(image_path='data/images/21.png',\n",
    "                                        filter_r = (0, 255),\n",
    "                                        filter_g = (0, 0),\n",
    "                                        filter_b = (0, 255))\n",
    "\n",
    "# Calculate MSE for the images\n",
    "rmse_2_1_filter = calc_rmse_images(image1 = np.array(Image.open(\"data/images/2.jpg\")), image2 = np.array(image_2_1_filter))\n",
    "rmse_2_2_filter = calc_rmse_images(image1 = np.array(Image.open(\"data/images/2.jpg\")), image2 = np.array(image_2_2_filter))\n",
    "rmse_21_1_filter = calc_rmse_images(image1 = np.array(Image.open(\"data/images/21.png\")), image2 = np.array(image_21_1_filter))\n",
    "rmse_21_2_filter = calc_rmse_images(image1 = np.array(Image.open(\"data/images/21.png\")), image2 = np.array(image_21_2_filter))\n",
    "\n",
    "# Calculate PSNR for the images\n",
    "psnr_2_1_filter = peak_signal_noise_ratio(np.array(Image.open(\"data/images/2.jpg\")), np.array(image_2_1_filter))\n",
    "psnr_2_2_filter = peak_signal_noise_ratio(np.array(Image.open(\"data/images/2.jpg\")), np.array(image_2_2_filter))\n",
    "psnr_21_1_filter = peak_signal_noise_ratio(np.array(Image.open(\"data/images/21.png\")), np.array(image_21_1_filter))\n",
    "psnr_21_2_filter = peak_signal_noise_ratio(np.array(Image.open(\"data/images/21.png\")), np.array(image_21_2_filter))\n",
    "\n",
    "# visualize images in 2x3 grid\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 12))\n",
    "axes[0, 1].imshow(Image.open(\"data/images/2.jpg\"))\n",
    "axes[0, 1].axis('off')\n",
    "axes[0, 1].set_title(f\"Originalbild \\nRMSE: {rmse_2:.2f}, PSNR: {psnr_2:.2f}\" , fontsize=10)\n",
    "axes[0, 2].imshow(image_2_1_filter)\n",
    "axes[0, 2].axis('off')\n",
    "axes[0, 2].set_title(f\"Rotkanal gefiltert\\nRMSE: {rmse_2_1_filter:.2f}, PSNR: {psnr_2_1_filter:.2f}\", fontsize=10)\n",
    "axes[0, 0].imshow(image_2_2_filter)\n",
    "axes[0, 0].axis('off')\n",
    "axes[0, 0].set_title(f\"Grünkanal gefiltert\\nRMSE: {rmse_2_2_filter:.2f}, PSNR: {psnr_2_2_filter:.2f}\", fontsize=10)\n",
    "axes[1, 1].imshow(Image.open(\"data/images/21.png\"))\n",
    "axes[1, 1].axis('off')\n",
    "axes[1, 1].set_title(f\"Originalbild \\nRMSE: {rmse_21:.2f}, PSNR: {psnr_21:.2f}\", fontsize=10)\n",
    "axes[1, 2].imshow(image_21_1_filter)\n",
    "axes[1, 2].axis('off')\n",
    "axes[1, 2].set_title(f\"Rotkanal gefiltert\\nRMSE: {rmse_21_1_filter:.2f}, PSNR: {psnr_21_1_filter:.2f}\", fontsize=10)\n",
    "axes[1, 0].imshow(image_21_2_filter)\n",
    "axes[1, 0].axis('off')\n",
    "axes[1, 0].set_title(f\"Grünkanal gefiltert\\nRMSE: {rmse_21_2_filter:.2f}, PSNR: {psnr_21_2_filter:.2f}\", fontsize=10)\n",
    "\n",
    "plt.subplots_adjust(wspace=0.1, hspace=0.1)\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.suptitle(\"Rotkanal & Grünkanal filtern\", fontsize=20, y=0.9)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogramm der Bilder\n",
    "image_and_histo(image1=np.array(Image.open(\"data/images/2.jpg\")),\n",
    "                image2=np.array(image_2_1_filter),\n",
    "                title1=\"Originalbild\",\n",
    "                title2=\"Rotkanal gefiltert\",\n",
    "                log_scale=True)\n",
    "\n",
    "image_and_histo(image1=np.array(Image.open(\"data/images/2.jpg\")),\n",
    "                image2=np.array(image_2_2_filter),\n",
    "                title1=\"Originalbild\",\n",
    "                title2=\"Grünkanal gefiltert\",\n",
    "                log_scale=True)\n",
    "\n",
    "image_and_histo(image1=np.array(Image.open(\"data/images/21.png\")),\n",
    "                image2=np.array(image_21_1_filter),\n",
    "                title1=\"Originalbild\",\n",
    "                title2=\"Rotkanal gefiltert\",\n",
    "                log_scale=True)\n",
    "\n",
    "image_and_histo(image1=np.array(Image.open(\"data/images/21.png\")),\n",
    "                image2=np.array(image_21_2_filter),\n",
    "                title1=\"Originalbild\",\n",
    "                title2=\"Grünkanal gefiltert\",\n",
    "                log_scale=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.5 Experiment Schärfe\n",
    "\n",
    "In Experiment Schärfe, versuchen wir einerseits das Bild mittels Filtern (Kernel) zu schärfen. \n",
    "Weiter versuchen wir auch, die Bilder mittels einer selbst implementierten Gausschen Weichzeichenfilter zu verschwimmen und schauen uns die Resultate dann an. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.5.1 Experiment durch Filter\n",
    "\n",
    "Wir schreiben eine Funktion, die es uns erlaubt, ein beliebiges Bild mit einem beliebigen Filter der Wahl zu filtern, um somit die Schärfe des Bildes zu erhöhen oder zu verringern und schauen, ob das Resultat unseren Erwartungen entspricht."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementierung der Convulution Filter\n",
    "def convolve2D(image: np.ndarray, kernel: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Convolves an image with a kernel.\n",
    "\n",
    "    Parameters:\n",
    "    image (np.ndarray): Input image (2D array).\n",
    "    kernel (np.ndarray): Kernel (2D array).\n",
    "\n",
    "    Returns:\n",
    "    np.ndarray: Convolved image.\n",
    "    \"\"\"\n",
    "    # Get the dimensions of the image and the kernel\n",
    "    image_height, image_width = image.shape\n",
    "    kernel_height, kernel_width = kernel.shape\n",
    "\n",
    "    # Allocate space for the output image\n",
    "    output = np.zeros_like(image, dtype=float)\n",
    "\n",
    "    # Compute the padding size for the image\n",
    "    pad_height = (kernel_height - 1) // 2\n",
    "    pad_width = (kernel_width - 1) // 2\n",
    "\n",
    "    # Pad the image with zeros\n",
    "    padded_image = np.pad(image, ((pad_height, pad_height), (pad_width, pad_width)), mode='constant')\n",
    "\n",
    "    # Perform convolution\n",
    "    for y in range(image_height):\n",
    "        for x in range(image_width):\n",
    "            region = padded_image[y:y + kernel_height, x:x + kernel_width]\n",
    "            output[y, x] = np.sum(region * kernel)\n",
    "\n",
    "    return output\n",
    "\n",
    "def image_sharpness(image: np.ndarray, kernel: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Sharpens an image using a specified convolution kernel.\n",
    "    \n",
    "    Parameters:\n",
    "    image (np.ndarray): The input image as a Numpy array with shape (height, width, 3).\n",
    "    kernel (np.ndarray): The convolution kernel used for image sharpening.\n",
    "\n",
    "    Returns:\n",
    "    np.ndarray: The sharpened image.\n",
    "    \"\"\"\n",
    "    # Ensure image has the correct shape\n",
    "    if image.ndim != 3 or image.shape[2] != 3:\n",
    "        raise ValueError(\"The input image must have the shape (height, width, 3).\")\n",
    "    \n",
    "    # Initialize the output image\n",
    "    sharpened = np.zeros_like(image, dtype=np.float32)\n",
    "\n",
    "    # Apply the convolution kernel to each channel separately\n",
    "    for channel in range(3):\n",
    "        sharpened[:, :, channel] = convolve2D(image[:, :, channel].astype(float), kernel)\n",
    "    \n",
    "    # Clip values to be in the valid range and convert back to uint8\n",
    "    np.clip(sharpened, 0, 255, out=sharpened)\n",
    "    sharpened = sharpened.astype(np.uint8)\n",
    "    \n",
    "    return sharpened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test functino image_sharpness\n",
    "# Create a sharpening kernel\n",
    "kernel = np.array([[-1, -1, -1],\n",
    "                   [-1,  9, -1],\n",
    "                   [-1, -1, -1]])\n",
    "\n",
    "# Apply the kernel to the image\n",
    "image_10_sharp = image_sharpness(image=np.array(Image.open(\"data/images/10.jpg\")), \n",
    "                                 kernel=np.array([[-1, -1, -1],\n",
    "                                                  [-1,  9, -1],\n",
    "                                                  [-1, -1, -1]]))\n",
    "\n",
    "image_19_sharp = image_sharpness(image=np.array(Image.open(\"data/images/19.jpg\")),\n",
    "                                    kernel=np.array([[-1, -1, -1],\n",
    "                                                    [-1,  9, -1],\n",
    "                                                    [-1, -1, -1]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate MSE for the images\n",
    "rmse_10_sharp = calc_rmse_images(image1 = np.array(Image.open(\"data/images/10.jpg\")), image2 = np.array(image_10_sharp))\n",
    "rmse_19_sharp = calc_rmse_images(image1 = np.array(Image.open(\"data/images/19.jpg\")), image2 = np.array(image_19_sharp))\n",
    "# calculate MSE for orginal image\n",
    "rmse_10 = calc_rmse_images(image1 = np.array(Image.open(\"data/images/10.jpg\")), image2 = np.array(Image.open(\"data/images/10.jpg\")).copy())\n",
    "rmse_19 = calc_rmse_images(image1 = np.array(Image.open(\"data/images/19.jpg\")), image2 = np.array(Image.open(\"data/images/19.jpg\")).copy())\n",
    "\n",
    "# Calculate PSNR for the images\n",
    "psnr_10_sharp = peak_signal_noise_ratio(np.array(Image.open(\"data/images/10.jpg\")), np.array(image_10_sharp))\n",
    "psnr_19_sharp = peak_signal_noise_ratio(np.array(Image.open(\"data/images/19.jpg\")), np.array(image_19_sharp))\n",
    "# calculate psnr for orginal image\n",
    "psnr_10 = peak_signal_noise_ratio(np.array(Image.open(\"data/images/10.jpg\")), np.array(Image.open(\"data/images/10.jpg\")).copy())\n",
    "psnr_19 = peak_signal_noise_ratio(np.array(Image.open(\"data/images/19.jpg\")), np.array(Image.open(\"data/images/19.jpg\")).copy())\n",
    "\n",
    "# visualize images in 2x2 grid\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "axes[0, 0].imshow(Image.open(\"data/images/10.jpg\"))\n",
    "axes[0, 0].axis('off')\n",
    "axes[0, 0].set_title(f\"Originalbild\\nRMSE: {rmse_10:.2f}, PSNR: {psnr_10:.2f}\", fontsize=10)\n",
    "axes[0, 1].imshow(image_10_sharp)\n",
    "axes[0, 1].axis('off')\n",
    "axes[0, 1].set_title(f\"Sharpness\\nRMSE: {rmse_10_sharp:.2f}, PSNR: {psnr_10_sharp:.2f}\", fontsize=10)\n",
    "\n",
    "axes[1, 0].imshow(Image.open(\"data/images/19.jpg\"))\n",
    "axes[1, 0].axis('off')\n",
    "axes[1, 0].set_title(f\"Originalbild\\nRMSE: {rmse_19:.2f}, PSNR: {psnr_19:.2f}\", fontsize=10)\n",
    "axes[1, 1].imshow(image_19_sharp)\n",
    "axes[1, 1].axis('off')\n",
    "axes[1, 1].set_title(f\"Sharpness\\nRMSE: {rmse_19_sharp:.2f}, PSNR: {psnr_19_sharp:.2f}\", fontsize=10)\n",
    "\n",
    "plt.subplots_adjust(wspace=0.1, hspace=0.1)\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.suptitle(\"Bildschärfe\", fontsize=20, y=1)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogramm der Bilder\n",
    "image_and_histo(image1=np.array(Image.open(\"data/images/10.jpg\")),\n",
    "                image2=np.array(image_10_sharp),\n",
    "                title1=\"Originalbild\",\n",
    "                title2=\"Geschärftes Bild\",\n",
    "                log_scale=True)\n",
    "\n",
    "image_and_histo(image1=np.array(Image.open(\"data/images/19.jpg\")),\n",
    "                image2=np.array(image_19_sharp),\n",
    "                title1=\"Originalbild\",\n",
    "                title2=\"Geschärftes Bild\",\n",
    "                log_scale=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.5.2 Experiment mit Gausschen Weichzeichenfilter\n",
    "\n",
    "Auch hier schreiben wir eine Funktion, analog der vorherhigen, einfach das die Filterwerte durch eine Normalverteilung generiert werden und erhoffen uns somit ein verschwommenes Bil zu erhalten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_kernel(size: int, sigma: float):\n",
    "    \"\"\"Generates a Gaussian kernel.\"\"\"\n",
    "    kernel = np.fromfunction(lambda x, y: (1/ (2 * np.pi * sigma ** 2)) * \n",
    "                             np.exp(- ((x - (size - 1) / 2) ** 2 + (y - (size - 1) / 2) ** 2) / (2 * sigma ** 2)),\n",
    "                             (size, size))\n",
    "    return kernel / np.sum(kernel)\n",
    "\n",
    "def gaussian_filter(image: np.ndarray, sigma: float) -> np.ndarray:\n",
    "    \"\"\"Applies a Gaussian filter to an image.\"\"\"\n",
    "    size = int(6 * sigma + 1)\n",
    "    size = size + 1 if size % 2 == 0 else size  # size must be odd\n",
    "    kernel = gaussian_kernel(size, sigma)\n",
    "    return convolve2D(image, kernel)\n",
    "\n",
    "\n",
    "def blurry_image(image: np.ndarray, sigma: float) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Blurs an image using a specified sigma value for the Gaussian filter.\n",
    "    \n",
    "    Parameters:\n",
    "    image (np.ndarray): The input image as a Numpy array with shape (height, width, 3).\n",
    "    sigma (float): The sigma value used for the Gaussian blur.\n",
    "\n",
    "    Returns:\n",
    "    np.ndarray: The blurred image.\n",
    "    \"\"\"\n",
    "    # Ensure image has the correct shape\n",
    "    if image.ndim != 3 or image.shape[2] != 3:\n",
    "        raise ValueError(\"The input image must have the shape (height, width, 3).\")\n",
    "    \n",
    "    # Initialize the output image\n",
    "    blurred = np.zeros_like(image, dtype=np.float32)\n",
    "\n",
    "    # Apply the Gaussian filter to each channel separately\n",
    "    for channel in range(3):\n",
    "        blurred[:, :, channel] = gaussian_filter(image[:, :, channel].astype(float), sigma)\n",
    "    \n",
    "    # Clip values to be in the valid range and convert back to uint8\n",
    "    np.clip(blurred, 0, 255, out=blurred)\n",
    "    blurred = blurred.astype(np.uint8)\n",
    "    \n",
    "    return blurred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test function blurry_image\n",
    "# Apply the kernel to the image\n",
    "image_10_blurry = blurry_image(image=np.array(Image.open(\"data/images/10.jpg\")), \n",
    "                               sigma=2.0)\n",
    "\n",
    "image_19_blurry = blurry_image(image=np.array(Image.open(\"data/images/19.jpg\")),\n",
    "                               sigma=5.0)\n",
    "\n",
    "# Calculate MSE for the images\n",
    "rmse_10_blurry = calc_rmse_images(image1 = np.array(Image.open(\"data/images/10.jpg\")), image2 = np.array(image_10_blurry))\n",
    "rmse_19_blurry = calc_rmse_images(image1 = np.array(Image.open(\"data/images/19.jpg\")), image2 = np.array(image_19_blurry))\n",
    "\n",
    "# Calculate PSNR for the images\n",
    "psnr_10_blurry = peak_signal_noise_ratio(np.array(Image.open(\"data/images/10.jpg\")), np.array(image_10_blurry))\n",
    "psnr_19_blurry = peak_signal_noise_ratio(np.array(Image.open(\"data/images/19.jpg\")), np.array(image_19_blurry))\n",
    "\n",
    "\n",
    "# visualize images in 2x2 grid\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "axes[0, 0].imshow(Image.open(\"data/images/10.jpg\"))\n",
    "axes[0, 0].axis('off')\n",
    "axes[0, 0].set_title(f\"Originalbild\\nRMSE: {rmse_10:.2f}, PSNR: {psnr_10:.2f}\", fontsize=10)\n",
    "axes[0, 1].imshow(image_10_blurry)\n",
    "axes[0, 1].axis('off')\n",
    "axes[0, 1].set_title(f\"Verwischtes Bild\\nRMSE: {rmse_10_blurry:.2f}, PSNR: {psnr_10_blurry:.2f}\", fontsize=10)\n",
    "\n",
    "axes[1, 0].imshow(Image.open(\"data/images/19.jpg\"))\n",
    "axes[1, 0].axis('off')\n",
    "axes[1, 0].set_title(f\"Originalbild\\nRMSE: {rmse_19:.2f}, PSNR: {psnr_19:.2f}\", fontsize=10)\n",
    "axes[1, 1].imshow(image_19_blurry)\n",
    "axes[1, 1].axis('off')\n",
    "axes[1, 1].set_title(f\"Verwischtes Bild\\nRMSE: {rmse_19_blurry:.2f}, PSNR: {psnr_19_blurry:.2f}\", fontsize=10)\n",
    "\n",
    "plt.subplots_adjust(wspace=0.1, hspace=0.1)\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.suptitle(\"Bildunschärfe\", fontsize=20, y=1)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogramm der Bilder\n",
    "image_and_histo(image1=np.array(Image.open(\"data/images/10.jpg\")),\n",
    "                image2=np.array(image_10_blurry),\n",
    "                title1=\"Originalbild\",\n",
    "                title2=\"Verwischtes Bild\")\n",
    "\n",
    "image_and_histo(image1=np.array(Image.open(\"data/images/19.jpg\")),\n",
    "                image2=np.array(image_19_blurry),\n",
    "                title1=\"Originalbild\",\n",
    "                title2=\"Verwischtes Bild\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.6 Experiment Farbräume (Korrektur oder Transformationen)\n",
    "\n",
    "In diesem Experiment versuchen wir eine Helligkeitskorrektur durchzuführen. \n",
    "Weiter untersuchen wir die das HSV-Farbmodell und schauen uns die Bilder an, ob diese denn tatsächlich Lebendiger, Reiner sind."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.6.1 Experiment Helligkeitskorrektur\n",
    "\n",
    "In diesem Experiment versuchen wir die Helligkeit der Biler zu erhöhen indem wir die Bilder in den LSV-Farbraum konvertieren und anschliessend die Helligkeit (luminance) verändern un schauen uns an, was mit den Bildern geschieht."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_brightness_lab(image: np.ndarray, factor: float) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Adjusts the brightness of an image in the LAB color space.\n",
    "\n",
    "    Parameters:\n",
    "    image (np.ndarray): The input image as a Numpy array with shape (height, width, 3).\n",
    "    factor (float): The factor by which to adjust the brightness in the L channel.\n",
    "                    A factor of 1.0 means no change. Values can be above or below 1 to increase or decrease brightness, respectively.\n",
    "\n",
    "    Returns:\n",
    "    np.ndarray: The image with adjusted brightness.\n",
    "    \"\"\"\n",
    "    # Ensure image has the correct shape and normalize to range [0, 1]\n",
    "    if image.ndim != 3 or image.shape[2] != 3:\n",
    "        raise ValueError(\"The input image must have the shape (height, width, 3).\")\n",
    "    image = image / 255.0 if image.dtype == np.uint8 else image\n",
    "    \n",
    "    # Convert image to LAB color space\n",
    "    lab_image = color.rgb2lab(image)\n",
    "    \n",
    "    # Adjust the L channel by the specified factor\n",
    "    lab_image[:, :, 0] = np.clip(lab_image[:, :, 0] * factor, 0, 100)\n",
    "    \n",
    "    # Convert back to RGB color space\n",
    "    rgb_image = color.lab2rgb(lab_image)\n",
    "    \n",
    "    # If the original image was uint8, convert back to uint8\n",
    "    if image.dtype == np.uint8:\n",
    "        rgb_image = (rgb_image * 255).astype(np.uint8)\n",
    "    \n",
    "    return rgb_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test function adjust_brightness_lab\n",
    "image_11_bright = adjust_brightness_lab(image=np.array(Image.open(\"data/images/11.jpg\")), \n",
    "                                        factor=1.5)\n",
    "\n",
    "image_22_bright = adjust_brightness_lab(image=np.array(Image.open(\"data/images/22.png\")),\n",
    "                                        factor=0.5)\n",
    "\n",
    "# Calculate MSE for the images\n",
    "rmse_11_bright = calc_rmse_images(image1 = np.array(Image.open(\"data/images/11.jpg\")), image2 = np.array(image_11_bright))\n",
    "rmse_22_bright = calc_rmse_images(image1 = np.array(Image.open(\"data/images/22.png\")), image2 = np.array(image_22_bright))\n",
    "# calculate MSE for orginal image\n",
    "rmse_11 = calc_rmse_images(image1 = np.array(Image.open(\"data/images/11.jpg\")), image2 = np.array(Image.open(\"data/images/11.jpg\")).copy())\n",
    "rmse_22 = calc_rmse_images(image1 = np.array(Image.open(\"data/images/22.png\")), image2 = np.array(Image.open(\"data/images/22.png\")).copy())\n",
    "\n",
    "# Calculate PSNR for the images\n",
    "psnr_11_bright = peak_signal_noise_ratio(np.array(Image.open(\"data/images/11.jpg\")), np.array(image_11_bright))\n",
    "psnr_22_bright = peak_signal_noise_ratio(np.array(Image.open(\"data/images/22.png\")), np.array(image_22_bright))\n",
    "# calculate psnr for orginal image\n",
    "psnr_11 = peak_signal_noise_ratio(np.array(Image.open(\"data/images/11.jpg\")), np.array(Image.open(\"data/images/11.jpg\")).copy())\n",
    "psnr_22 = peak_signal_noise_ratio(np.array(Image.open(\"data/images/22.png\")), np.array(Image.open(\"data/images/22.png\")).copy())\n",
    "\n",
    "# visualize images in 2x2 grid\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "axes[0, 0].imshow(Image.open(\"data/images/11.jpg\"))\n",
    "axes[0, 0].axis('off')\n",
    "axes[0, 0].set_title(f\"Originalbild\\nRMSE: {rmse_11:.2f}, PSNR: {psnr_11:.2f}\", fontsize=10)\n",
    "axes[0, 1].imshow(image_11_bright)\n",
    "axes[0, 1].axis('off')\n",
    "axes[0, 1].set_title(f\"Helleres Bild\\nRMSE: {rmse_11_bright:.2f}, PSNR: {psnr_11_bright:.2f}\", fontsize=10)\n",
    "\n",
    "axes[1, 0].imshow(Image.open(\"data/images/22.png\"))\n",
    "axes[1, 0].axis('off')\n",
    "axes[1, 0].set_title(f\"Originalbild\\nRMSE: {rmse_22:.2f}, PSNR: {psnr_22:.2f}\", fontsize=10)\n",
    "axes[1, 1].imshow(image_22_bright)\n",
    "axes[1, 1].axis('off')\n",
    "axes[1, 1].set_title(f\"Helleres Bild\\nRMSE: {rmse_22_bright:.2f}, PSNR: {psnr_22_bright:.2f}\", fontsize=10)\n",
    "\n",
    "plt.subplots_adjust(wspace=0.1, hspace=0.1)\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.suptitle(\"Helligkeit\", fontsize=20, y=1)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogramm der Bilder\n",
    "image_and_histo(image1=np.array(Image.open(\"data/images/11.jpg\")),\n",
    "                image2=np.array(image_11_bright),\n",
    "                title1=\"Originalbild\",\n",
    "                title2=\"Helleres Bild\",\n",
    "                log_scale=True)\n",
    "\n",
    "image_and_histo(image1=np.array(Image.open(\"data/images/22.png\")),\n",
    "                image2=np.array(image_22_bright),\n",
    "                title1=\"Originalbild\",\n",
    "                title2=\"Dunkleres Bild\",\n",
    "                log_scale=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.6.2 Experiment HSV-Farbmodell\n",
    "\n",
    "In diesem Experiment spielen wir mit den Werten von V im HSV-Farbmodell, indem wir einen Histogramm-Equalizer auf den V-Kanal anwenden und schauen uns die Resultate an."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_contrast_hsv(image: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Adjusts the brightness of an image in the HSV color space using histogram equalization.\n",
    "\n",
    "    Parameters:\n",
    "    image (np.ndarray): The input image as a Numpy array with shape (height, width, 3).\n",
    "\n",
    "    Returns:\n",
    "    np.ndarray: The image with adjusted brightness.\n",
    "    \"\"\"\n",
    "    # Ensure image has the correct shape\n",
    "    if image.ndim != 3 or image.shape[2] != 3:\n",
    "        raise ValueError(\"The input image must have the shape (height, width, 3).\")\n",
    "\n",
    "    # Convert image to HSV color space\n",
    "    hsv_image = color.rgb2hsv(image)\n",
    "    \n",
    "    # Apply histogram equalization to the V channel\n",
    "    hsv_image[:, :, 2] = exposure.equalize_hist(hsv_image[:, :, 2], nbins=256, mask=1)\n",
    "    \n",
    "    # Convert back to RGB color space\n",
    "    rgb_image = color.hsv2rgb(hsv_image)\n",
    "    \n",
    "    # Convert back to uint8 if necessary\n",
    "    if image.dtype == np.uint8:\n",
    "        rgb_image = (rgb_image * 255).astype(np.uint8)\n",
    "    \n",
    "    return rgb_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test function adjust_brightness_lab\n",
    "image_11_bright = adjust_contrast_hsv(image=np.array(Image.open(\"data/images/11.jpg\")))\n",
    "image_22_bright = adjust_contrast_hsv(image=np.array(Image.open(\"data/images/22.png\")))\n",
    "\n",
    "# Calculate MSE for the images\n",
    "rmse_11_bright = calc_rmse_images(image1 = np.array(Image.open(\"data/images/11.jpg\")), image2 = np.array(image_11_bright))\n",
    "rmse_22_bright = calc_rmse_images(image1 = np.array(Image.open(\"data/images/22.png\")), image2 = np.array(image_22_bright))\n",
    "\n",
    "# Calculate PSNR for the images\n",
    "psnr_11_bright = peak_signal_noise_ratio(np.array(Image.open(\"data/images/11.jpg\")), np.array(image_11_bright))\n",
    "psnr_22_bright = peak_signal_noise_ratio(np.array(Image.open(\"data/images/22.png\")), np.array(image_22_bright))\n",
    "\n",
    "# visualize images in 2x2 grid\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "axes[0, 0].imshow(Image.open(\"data/images/11.jpg\"))\n",
    "axes[0, 0].axis('off')\n",
    "axes[0, 0].set_title(f\"Originalbild\\nRMSE: {rmse_11:.2f}, PSNR: {psnr_11:.2f}\", fontsize=10)\n",
    "axes[0, 1].imshow(image_11_bright)\n",
    "axes[0, 1].axis('off')\n",
    "axes[0, 1].set_title(f\"Kontraständerung\\nRMSE: {rmse_11_bright:.2f}, PSNR: {psnr_11_bright:.2f}\", fontsize=10)\n",
    "\n",
    "axes[1, 0].imshow(Image.open(\"data/images/22.png\"))\n",
    "axes[1, 0].axis('off')\n",
    "axes[1, 0].set_title(f\"Originalbild\\nRMSE: {rmse_22:.2f}, PSNR: {psnr_22:.2f}\", fontsize=10)\n",
    "axes[1, 1].imshow(image_22_bright)\n",
    "axes[1, 1].axis('off')\n",
    "axes[1, 1].set_title(f\"Kontraständerung\\nRMSE: {rmse_22_bright:.2f}, PSNR: {psnr_22_bright:.2f}\", fontsize=10)\n",
    "\n",
    "plt.subplots_adjust(wspace=0.1, hspace=0.1)\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.suptitle(\"Kontraständerung\", fontsize=20, y=1)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogramm der Bilder\n",
    "image_and_histo(image1=np.array(Image.open(\"data/images/11.jpg\")),\n",
    "                image2=np.array(image_11_bright),\n",
    "                title1=\"Originalbild\",\n",
    "                title2=\"Kontraständerung\",\n",
    "                log_scale=True)\n",
    "\n",
    "image_and_histo(image1=np.array(Image.open(\"data/images/22.png\")),\n",
    "                image2=np.array(image_22_bright),\n",
    "                title1=\"Originalbild\",\n",
    "                title2=\"Kontraständerung\",\n",
    "                log_scale=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Signaleigenschaften\n",
    "Suche verschiedene Signale unterschiedlicher Szenen passend zu deinem Land oder nehme selbst welche auf. Die Signale sollen sich eignen, um Anpassungen der Signaleigenschaften {'Bandbreite, Phase, Rauschen'} in Experimenten zu demonstrieren. Messe dazu zuerst auf deinen Signalen die dir zugeordneten Signaleigenschaften mittels geeigneten Metriken. Definiere danach ein Ziel, wie die dir zugeordneten Signaleigenschaften verändert werden sollen. Definiere ein paar Experimente, um dieses Ziel zu erreichen, und führe die Experimente mit deinen Signalen und geeigneten Methoden aus. Demonstriere mit deinen aufgenommenen Signale das Nyquist Theorem. Diskutiere deine Daten-, Parameter- und Methodenwahl und die erzielten Ergebnisse. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Signal Daten einlesen\n",
    "from IPython.display import Audio\n",
    "# Konvertierung\n",
    "from pydub import AudioSegment\n",
    "# Librosa\n",
    "import librosa\n",
    "\n",
    "# soundfile\n",
    "import soundfile as sf\n",
    "\n",
    "# wavfile einlesen\n",
    "from scipy.io import wavfile\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1 Signale Laden\n",
    "\n",
    "Auch bei den Signal Daten haben wir ein Pool von fünf Daten die wir für unsere Experimente verwenden können. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_files = [\"1.wav\", \"2.wav\", \"3.wav\", \"4.wav\", \"5.wav\"]\n",
    "\n",
    "for file in audio_files:\n",
    "    print(f\"Signal: {file}\")\n",
    "    display(Audio(filename=f\"data/signals/{file}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2 Signale selektieren & geeignete Metriken\n",
    "\n",
    "Eine Eigenschaft von Signalen die wir visualisieren können ist das Amplitude-Frequenz-Spektrum, welches wir als Funktion hinschreiben. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to plot the signal amplitude vs time\n",
    "def plot_signal(file_path, sample_rate=44100):\n",
    "    # Load audio file\n",
    "    audio, _ = librosa.load(file_path, sr=sample_rate)\n",
    "\n",
    "    # Create time array\n",
    "    time = np.arange(0, len(audio))/sample_rate\n",
    "\n",
    "    # Plot the signal\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    plt.plot(time, audio)\n",
    "    plt.xlabel(\"Time (seconds)\")\n",
    "    plt.ylabel(\"Amplitude\")\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "# Createa a function to plot the spectrum\n",
    "def plot_single_spectrum(file_path, title):\n",
    "    \n",
    "    # Load the audio file\n",
    "    audio_data, sample_rate = librosa.load(file_path, sr=None)\n",
    "    \n",
    "    # Calculate the spectrum\n",
    "    fft_result = np.fft.fft(audio_data)\n",
    "    frequencies = np.fft.fftfreq(len(fft_result), 1.0 / sample_rate)\n",
    "\n",
    "    # Visualize the spectrum\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.plot(frequencies, np.abs(fft_result))\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Frequenz (Hz)\")\n",
    "    plt.ylabel(\"Amplitude\")\n",
    "    plt.show()\n",
    "\n",
    "    # Create a function thath uses both function above to visualize the spectrum next to each other \n",
    "def plot_signal_and_spectrum(file_path, title):\n",
    "    # Load the audio file\n",
    "    audio_data, sample_rate = librosa.load(file_path, sr=None)\n",
    "    \n",
    "    # Create time array\n",
    "    time = np.arange(0, len(audio_data))/sample_rate\n",
    "    \n",
    "    # Calculate the spectrum\n",
    "    fft_result = np.fft.fft(audio_data)\n",
    "    frequencies = np.fft.fftfreq(len(fft_result), 1.0 / sample_rate)\n",
    "\n",
    "    # Visualize the signal and the spectrum\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    axes[0].plot(time, audio_data)\n",
    "    axes[0].set_xlabel(\"Time (seconds)\")\n",
    "    axes[0].set_ylabel(\"Amplitude\")\n",
    "    axes[0].set_title(\"Visualization of Recording\")\n",
    "    axes[1].plot(frequencies, np.abs(fft_result))\n",
    "    axes[1].set_xlabel(\"Frequenz (Hz)\")\n",
    "    axes[1].set_ylabel(\"Amplitude\")\n",
    "    axes[1].set_title(\"Visualization of Spectrum\")\n",
    "    fig.suptitle(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_compare_signals_and_spectrums(file_path1, file_path2, title_1, title_2):\n",
    "    # Load the first audio file\n",
    "    audio_data1, sample_rate1 = librosa.load(file_path1, sr=None)\n",
    "    \n",
    "    # Calculate the spectrum for the first audio file\n",
    "    fft_result1 = np.fft.fft(audio_data1)\n",
    "    frequencies1 = np.fft.fftfreq(len(fft_result1), 1.0 / sample_rate1)\n",
    "    \n",
    "    # Time for the first audio file\n",
    "    time1 = np.arange(0, len(audio_data1))/sample_rate1\n",
    "    \n",
    "    # Load the second audio file\n",
    "    audio_data2, sample_rate2 = librosa.load(file_path2, sr=None)\n",
    "    \n",
    "    # Calculate the spectrum for the second audio file\n",
    "    fft_result2 = np.fft.fft(audio_data2)\n",
    "    frequencies2 = np.fft.fftfreq(len(fft_result2), 1.0 / sample_rate2)\n",
    "    \n",
    "    # Time for the second audio file\n",
    "    time2 = np.arange(0, len(audio_data2))/sample_rate2\n",
    "    \n",
    "    # Create a figure with 2x2 subplots\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # Plot the first signal\n",
    "    axs[0, 0].plot(time1, audio_data1)\n",
    "    axs[0, 0].set_title(f'Signal of {title_1}')\n",
    "    axs[0, 0].set_xlabel('Time (seconds)')\n",
    "    axs[0, 0].set_ylabel('Amplitude')\n",
    "    \n",
    "    # Plot the second signal\n",
    "    axs[1, 0].plot(time2, audio_data2)\n",
    "    axs[1, 0].set_title(f'Signal of {title_2}')\n",
    "    axs[1, 0].set_xlabel('Time (seconds)')\n",
    "    axs[1, 0].set_ylabel('Amplitude')\n",
    "    \n",
    "    # Plot the first spectrum\n",
    "    axs[0, 1].plot(frequencies1, np.abs(fft_result1))\n",
    "    axs[0, 1].set_title(f'Spectrum of {title_1}')\n",
    "    axs[0, 1].set_xlabel('Frequency (Hz)')\n",
    "    axs[0, 1].set_ylabel('Amplitude')\n",
    "    \n",
    "    # Plot the second spectrum\n",
    "    axs[1, 1].plot(frequencies2, np.abs(fft_result2))\n",
    "    axs[1, 1].set_title(f'Spectrum of {title_2}')\n",
    "    axs[1, 1].set_xlabel('Frequency (Hz)')\n",
    "    axs[1, 1].set_ylabel('Amplitude')\n",
    "    \n",
    "    # Adjust spacing and display plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_compare_spectrums(file_path1, file_path2, title_1, title_2):\n",
    "    # Load the first audio file\n",
    "    audio_data1, sample_rate1 = librosa.load(file_path1, sr=None)\n",
    "\n",
    "    # Calculate the spectrum for the first audio file\n",
    "    fft_result1 = np.fft.fft(audio_data1)\n",
    "    frequencies1 = np.fft.fftfreq(len(fft_result1), 1.0 / sample_rate1)\n",
    "\n",
    "    # Load the second audio file\n",
    "    audio_data2, sample_rate2 = librosa.load(file_path2, sr=None)\n",
    "\n",
    "    # Calculate the spectrum for the second audio file\n",
    "    fft_result2 = np.fft.fft(audio_data2)\n",
    "    frequencies2 = np.fft.fftfreq(len(fft_result2), 1.0 / sample_rate2)\n",
    "\n",
    "    # Create a figure with two subplots\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(25, 10))\n",
    "\n",
    "    # Plot the first spectrum\n",
    "    ax1.plot(frequencies1, np.abs(fft_result1))\n",
    "    ax1.set_title(title_1)\n",
    "    ax1.set_xlabel(\"Frequency (Hz)\")\n",
    "    ax1.set_ylabel(\"Amplitude\")\n",
    "\n",
    "    # Plot the second spectrum\n",
    "    ax2.plot(frequencies2, np.abs(fft_result2))\n",
    "    ax2.set_title(title_2)\n",
    "    ax2.set_xlabel(\"Frequency (Hz)\")\n",
    "    ax2.set_ylabel(\"Amplitude\")\n",
    "\n",
    "    plt.tight_layout()  # Ensure proper spacing between subplots\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.3 Ziel definieren\n",
    "\n",
    "\n",
    "| Experiment | Ziel | Signal |\n",
    "| --- | --- | --- |\n",
    "| Bandbreite | Das Ziel ist es die Brandbreite eines Signals beliebig filtern zu können  | 5.wav |\n",
    "| Phase | Eine Phasenverschiebung der Signale | 5.wav |\n",
    "| Rauschen |  |  | "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.4 Experiment Bandbreite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.4.1 Experiment durch Filtern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_frequency(file_path, filter_range=[0, None], output_file=\"filtered_audio.wav\", export=False):\n",
    "    \"\"\"\n",
    "    Load an audio file, compute its spectrum, filter it by frequency,\n",
    "    visualize the filtered spectrum, and save the filtered audio.\n",
    "\n",
    "    Parameters:\n",
    "    file_path (str): path to the audio file.\n",
    "    filter_range (list): list of two elements defining the start and end of the filter frequency range.\n",
    "    output_file (str): path to save the filtered audio file.\n",
    "    \"\"\"\n",
    "    # Load the audio file\n",
    "    audio_data, sample_rate = librosa.load(file_path, sr=None)\n",
    "    \n",
    "    # Compute the Fast Fourier Transform (FFT) of the audio data\n",
    "    fft_result = np.fft.fft(audio_data)\n",
    "    frequencies = np.fft.fftfreq(len(fft_result), 1.0 / sample_rate)\n",
    "\n",
    "    # Filter the FFT result\n",
    "    if filter_range[1] is None:\n",
    "        filter_range[1] = np.max(frequencies)\n",
    "    \n",
    "    filter_mask = (frequencies >= filter_range[0]) & (frequencies <= filter_range[1]) | \\\n",
    "                  (frequencies >= -filter_range[1]) & (frequencies <= -filter_range[0])\n",
    "                  \n",
    "    filtered_fft = fft_result.copy()\n",
    "    filtered_fft[~filter_mask] = 0  # Set the amplitudes outside the filter range to zero\n",
    "    \n",
    "    # Inverse FFT to convert back to time domain\n",
    "    filtered_audio = np.fft.ifft(filtered_fft).real\n",
    "\n",
    "    # if export is True, save the filtered audio\n",
    "    if export:\n",
    "        sf.write(output_file, filtered_audio, sample_rate)\n",
    "\n",
    "# Use function to filter audio signal in range [500, 1000] Hz\n",
    "filter_frequency(\"data/signals/5.mp3\", \n",
    "                 filter_range=[250, None], \n",
    "                 output_file=\"data/signals/filtered_5.wav\", \n",
    "                 export=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_experi1_files = [\"5.wav\", \"filtered_5.wav\"]\n",
    "\n",
    "for file in signal_experi1_files:\n",
    "    print(file)\n",
    "    display(Audio(filename=f\"data/signals/{file}\"))\n",
    "\n",
    "# Plot the spectrum\n",
    "plot_compare_signals_and_spectrums(file_path1='data/signals/5.wav',\n",
    "               file_path2='data/signals/filtered_5.wav',\n",
    "               title_1=\"Spectrum of 5.wav\",\n",
    "               title_2=\"Spectrum of filtered_5.wav\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.5 Experiment Phase\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.5.1 Experiment Phasenverschiebung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_phase(mp3_file_path, phase_shift, export=False, output_wav_file=None):\n",
    "    \"\"\"\n",
    "    Shifts the phase of an audio file and exports the result if necessary.\n",
    "\n",
    "    Parameters:\n",
    "    mp3_file_path (str): Path to the input mp3 file.\n",
    "    phase_shift (float): Phase shift to be applied.\n",
    "    export (bool): Flag to determine whether to export the shifted audio.\n",
    "    output_wav_file (str): Path to the output wav file if export is True.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load the audio file\n",
    "        y, sr = librosa.load(mp3_file_path)\n",
    "\n",
    "        # Compute the phase information\n",
    "        phase = librosa.stft(y)\n",
    "\n",
    "        # Shift the phase\n",
    "        phase_shifted = np.angle(phase) + phase_shift\n",
    "\n",
    "        # Inverse STFT to get the shifted audio\n",
    "        audio_shifted = librosa.istft(np.abs(phase) * np.exp(1j * phase_shifted))\n",
    "\n",
    "        # If export is True, save the shifted audio\n",
    "        if export and output_wav_file:\n",
    "            sf.write(output_wav_file, audio_shifted, sr)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "\n",
    "# Use function to shift phase of audio signal by pi/2\n",
    "shift_phase(mp3_file_path=\"data/signals/5.mp3\", \n",
    "            phase_shift=np.pi / 2, \n",
    "            export=True, \n",
    "            output_wav_file=\"data/signals/phase_shifted_5.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_shift_phase(file_path1, file_path2, title_1, title_2):\n",
    "    \"\"\"\n",
    "    Compares the phase information of two audio files visually.\n",
    "\n",
    "    Parameters:\n",
    "    file_path1 (str): Path to the first audio file.\n",
    "    file_path2 (str): Path to the second audio file.\n",
    "    title_1 (str): Title for the first plot.\n",
    "    title_2 (str): Title for the second plot.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load the audio files\n",
    "        y1, sr1 = librosa.load(file_path1)\n",
    "        y2, sr2 = librosa.load(file_path2)\n",
    "\n",
    "        # Compute the phase information\n",
    "        phase1 = librosa.stft(y1)\n",
    "        phase2 = librosa.stft(y2)\n",
    "\n",
    "        # Create comparison plots\n",
    "        plt.figure(figsize=(20, 6))\n",
    "\n",
    "        plt.subplot(1, 2, 1)\n",
    "        librosa.display.specshow(librosa.amplitude_to_db(np.abs(phase1), ref=np.max), y_axis='log', x_axis='time')\n",
    "        plt.colorbar(format='%+2.0f dB')\n",
    "        plt.title(title_1)\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        librosa.display.specshow(librosa.amplitude_to_db(np.abs(phase2), ref=np.max), y_axis='log', x_axis='time')\n",
    "        plt.colorbar(format='%+2.0f dB')\n",
    "        plt.title(title_2)\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_experi2_files = [\"5.wav\", \"phase_shifted_5.wav\"]\n",
    "\n",
    "for file in signal_experi2_files:\n",
    "    print(file)\n",
    "    display(Audio(filename=f\"data/signals/{file}\"))\n",
    "\n",
    "# Use function to compare phase of audio signal before and after phase shift\n",
    "compare_shift_phase(file_path1=\"data/signals/5.mp3\",\n",
    "                    file_path2=\"data/signals/phase_shifted_5.wav\",\n",
    "                    title_1=\"Phase of 5.mp3\",\n",
    "                    title_2=\"Phase of phase_shifted_5.wav\")\n",
    "\n",
    "# Plot the spectrum\n",
    "plot_compare_signals_and_spectrums(file_path1='data/signals/5.wav',\n",
    "               file_path2='data/signals/phase_shifted_5.wav',\n",
    "               title_1=\"Spectrum of 5.wav\",\n",
    "               title_2=\"Spectrum of phase_shifted_5.wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.6 Experiment Rauschen\n",
    "\n",
    "Wir versuchen aus dem Audio Signal das Rauschen zu minimieren indem wir einen Filter anwenden. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.6.1 Experiment 1-D Filter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_signal(file_path, filter, mode='valid', export=False, output_wav_file=None):\n",
    "    \"\"\"\n",
    "    Smooths a signal using 1D convolution.\n",
    "\n",
    "    Parameters:\n",
    "    signal (array-like): The input signal to be smoothed.\n",
    "    kernel (array-like): The convolution kernel.\n",
    "\n",
    "    Returns:\n",
    "    array: The smoothed signal.\n",
    "    \"\"\"\n",
    "    # Load audio with librosa\n",
    "    audio, sr = librosa.load(file_path)\n",
    "\n",
    "    # make sure the signal is a numpy array\n",
    "    filter = np.array(filter)\n",
    "    \n",
    "    # Apply convolution\n",
    "    smoothed_signal = np.convolve(audio, \n",
    "                                  filter,\n",
    "                                  mode)\n",
    "    # If export is True, save the smoothed audio\n",
    "    if export and output_wav_file:\n",
    "        sf.write(output_wav_file, smoothed_signal, sr)\n",
    "\n",
    "# Use function to smooth audio signal\n",
    "smooth_signal(file_path=\"data/signals/5.mp3\", \n",
    "              filter=[1/10] * 10, \n",
    "              export=True, \n",
    "              output_wav_file=\"data/signals/smoothed_5.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_experi3_files = [\"5.wav\", \"smoothed_5.wav\"]\n",
    "\n",
    "for file in signal_experi3_files:\n",
    "    print(file)\n",
    "    display(Audio(filename=f\"data/signals/{file}\"))\n",
    "\n",
    "# Plot the spectrum\n",
    "plot_compare_signals_and_spectrums(file_path1='data/signals/5.wav',\n",
    "               file_path2='data/signals/smoothed_5.wav',\n",
    "               title_1=\"Spectrum of 5.wav\",\n",
    "               title_2=\"Spectrum of smoothed_5.wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Normalisierung und Standardisierung\n",
    "Normalisiere und standardisiere deine Bild- und Signaldaten. Demonstriere, dass die Daten nach der Normalisierung/Standardisierung weiterhin den gleichen Inhalt zeigen. Diskutiere deine Methodenwahl und die erzielten Ergebnisse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Faltung/Filterung in Bild und Signal (LE2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Filterung in der räumlichen Domäne\n",
    "Implementiere selbst einen klassischen Algorithmus zur Filterung von Signalen (1D) und Bildern (2D) in der räumlichen Domäne (Faltung/Convolution). Welche Elemente soll ein solcher Algorithmus enthalten? Teste deine Funktion mit jeweils einem Signal und einem Bild passend zu deinem Land und zwei Faltungskernels in geeigneter Grösse. Die beiden Faltungskernel sollen das Signal bzw. Bild {'weichzeichnen, entrauschen'}. Skaliert dein Algorithmus für grosse Daten? Messe die Unterschiede deiner Beispielsignale/-bilder vor und nach dem Filtern mittels einer geeigneten Metrik. Diskutiere deine Daten-, Methoden- und Parameterwahl sowie die erzielten Ergebnisse. Weshalb hast du diese Faltungskernel bzw. diese Metrik gewählt? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Filterung in der spektralen Domäne\n",
    "Implementiere eine Methode basierend auf spektraler Filterung, welche ein repetitives Muster aus einem Signal bzw. einem Bild filtert. Die Methode soll für Signale (1D) sowie Bilder (2D) funktionieren. Demonstriere das Resultat anhand eines Signales und eines Bildes passend zu deinem Land. Diskutiere deine Daten-, Methoden- und Parameterwahl sowie die erzielten Ergebnisse. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Bonus: Filterung in der räumlichen und spektralen Domäne\n",
    "Führe optional Experimente mit Signalen oder Bildern mit Methoden durch, welche das Filtern in der räumlichen und der spektralen Domäne ermöglichen. Z.B. mittels Wavelets. Diskutiere deine Daten-, Parameter- und Methodenwahl und die erzielten Ergebnisse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4. Algorithmen zur Erkennung von Strukturen in Bildern\n",
    "Zeige die einzelnen Schritte eines bekannten klassischen Bildverarbeitungs-Algorithmus zur Detektion von {'Kreisen'} in einem geeigneten Beispielbild deines Landes. Die einzelnen Schritte können selbst programmiert sein oder von Bibliotheken verwendet werden. Wichtig ist, dass Zwischenergebnisse der Schritte ersichtlich sind. Beschreibe zudem, was in jedem einzelnen Schritt konzeptionell relevant ist. Diskutiere deine Daten-, Methoden- und Parameterwahl sowie die erzielten Ergebnisse. Für welche Fälle funktioniert dein Algorithmus gut bzw. schlecht? Warum hast du dieses Bild gewählt?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Peer-Grading\n",
    "Nach Abgabe der Mini-Challenge hast du 1 Woche Zeit eine dir zugeordnete Abgabe von anderen zu bewerten. Die Zuordnung erfolgt via FHNW Peer-Grading-Tool (siehe Link unten). Orientiere dich für die Bewertung an den vorgegebenen Bewertungskriterien (siehe Excel-Datei oder Peer-Grading-Tool). Die Note 5 bedeutet, dass alles erfüllt ist, wie du es von einem guten Data Scientist in der Praxis erwarten würdest. Du startest als Baseline mit der Note 5. Entdeckst du Fehler, geht die Note nach unten. Der Note 5.5 nähert man sich, wenn die Erwartungen übertroffen wurden. Der Note 6 nähert man sich, wenn die Leistung ausserordentlich oder mit einer unglaublichen Eigenleistung verbunden ist bzw. es gar nicht mehr besser geht. Kritisches Denken, Vielfalt von Experimenten und eigene Ideen werden positiv bewertet. Siehe auch Checkliste für Bewertung. Die Benotung soll auf Zehntel gerundet sein. Wer auf Zehntel gerundet mit 0.1 Abweichung die Endnote von der Fachexpertin trifft, kriegt einen Bonus von 0.2 Noten für die eigene Abgabe. In der Sprechstunde vom 7. November widmen wir uns dem Peer-Grading. \n",
    "FHNW Peer-Grading-Tool\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gbsv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
